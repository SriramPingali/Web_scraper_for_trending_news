{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sriram Pingali\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.cistem import Cistem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = Cistem()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting TOI Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class times_of_india():\n",
    "    def __init__(self):\n",
    "        self.root = 'https://timesofindia.indiatimes.com/'\n",
    "        self.page = requests.get(self.root)\n",
    "        self.soup = bs4.BeautifulSoup(self.page.text, 'lxml')\n",
    "        self.hreflinks = {}\n",
    "        self.redirects = []\n",
    "        self.database = []\n",
    "        self.imp_sections = ['div.top-story', 'div.tabcontent.mostshared', 'div.tabcontent.mostcommented','div.tabcontent.latest',  'div.tabcontent.mosttrending']\n",
    "        \n",
    "    def extract_href(self, imp_sections, soup, output):\n",
    "        for sections in imp_sections:\n",
    "            for section in soup.select(sections):\n",
    "                all_links = section.find_all(\"a\")\n",
    "                for link in all_links:\n",
    "                    if link.text[0:3] != 'See':\n",
    "                        self.hreflinks[link.text] = link['href']\n",
    "                    else:    \n",
    "                        output.append(link['href'])\n",
    "    \n",
    "    def extract_text(self):\n",
    "        self.extract_href(self.imp_sections, self.soup, self.redirects)\n",
    "        for redirect_link in self.redirects:\n",
    "            output_links = []\n",
    "            page_red = requests.get(self.root +\"/\" + redirect_link)\n",
    "            soup_red = bs4.BeautifulSoup(page_red.text, \"lxml\")\n",
    "            self.extract_href(['div.widget.box13'], soup_red, output_links)\n",
    "        for i, article_text in enumerate(self.hreflinks.values()):\n",
    "            page = requests.get(self.root + \"/\" + article_text)\n",
    "            soup = bs4.BeautifulSoup(page.text, 'lxml')\n",
    "            article = soup.select('div._3WlLe.clearfix')\n",
    "            if len(article):\n",
    "                self.database.append(preprocess(article[0].text))\n",
    "                with open(r\"./output/output_\" + str(i) + \".txt\" , \"w\",  encoding=\"utf-8\") as txt_file:\n",
    "                    txt_file.write(str(\"\") + article[0].text + str(\"\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "toi = times_of_india()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "toi.extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Dictionary & Bow Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(toi.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 thing\n",
      "1 temporary\n",
      "2 barricad\n",
      "3 sta\n",
      "4 bord\n",
      "5 stop\n",
      "6 peopl\n",
      "7 cross\n",
      "8 amid\n",
      "9 coronaviru\n",
      "10 pandemic\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in toi.database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 3 (\"sta\") appears 1 time.\n",
      "Word 6 (\"peopl\") appears 2 time.\n",
      "Word 28 (\"distric\") appears 2 time.\n",
      "Word 37 (\"stand\") appears 1 time.\n",
      "Word 61 (\"repor\") appears 2 time.\n",
      "Word 62 (\"covid\") appears 4 time.\n",
      "Word 63 (\"cas\") appears 5 time.\n",
      "Word 67 (\"monday\") appears 1 time.\n",
      "Word 96 (\"delhi\") appears 1 time.\n",
      "Word 97 (\"sunday\") appears 1 time.\n",
      "Word 99 (\"say\") appears 5 time.\n",
      "Word 115 (\"governm\") appears 1 time.\n",
      "Word 117 (\"work\") appears 1 time.\n",
      "Word 123 (\"hour\") appears 1 time.\n",
      "Word 141 (\"crisi\") appears 1 time.\n",
      "Word 148 (\"downloadth\") appears 1 time.\n",
      "Word 149 (\"tim\") appears 2 time.\n",
      "Word 150 (\"india\") appears 4 time.\n",
      "Word 151 (\"new\") appears 1 time.\n",
      "Word 152 (\"lat\") appears 1 time.\n",
      "Word 153 (\"daily\") appears 2 time.\n",
      "Word 154 (\"morning\") appears 2 time.\n",
      "Word 155 (\"newspap\") appears 1 time.\n",
      "Word 156 (\"order\") appears 1 time.\n",
      "Word 167 (\"tak\") appears 2 time.\n",
      "Word 169 (\"total\") appears 4 time.\n",
      "Word 171 (\"death\") appears 1 time.\n",
      "Word 173 (\"viru\") appears 1 time.\n",
      "Word 179 (\"numb\") appears 2 time.\n",
      "Word 185 (\"rat\") appears 1 time.\n",
      "Word 193 (\"positiv\") appears 1 time.\n",
      "Word 205 (\"control\") appears 1 time.\n",
      "Word 215 (\"country\") appears 2 time.\n",
      "Word 216 (\"ris\") appears 1 time.\n",
      "Word 219 (\"data\") appears 2 time.\n",
      "Word 228 (\"fresh\") appears 1 time.\n",
      "Word 331 (\"health\") appears 3 time.\n",
      "Word 453 (\"accord\") appears 1 time.\n",
      "Word 482 (\"day\") appears 2 time.\n",
      "Word 502 (\"secretary\") appears 1 time.\n",
      "Word 524 (\"area\") appears 1 time.\n",
      "Word 679 (\"help\") appears 1 time.\n",
      "Word 773 (\"ministry\") appears 4 time.\n",
      "Word 928 (\"april\") appears 1 time.\n",
      "Word 931 (\"spread\") appears 1 time.\n",
      "Word 1066 (\"urg\") appears 1 time.\n",
      "Word 1077 (\"availabl\") appears 1 time.\n",
      "Word 1080 (\"patie\") appears 1 time.\n",
      "Word 1100 (\"bring\") appears 1 time.\n",
      "Word 1215 (\"industry\") appears 1 time.\n",
      "Word 1239 (\"joi\") appears 1 time.\n",
      "Word 1256 (\"group\") appears 1 time.\n",
      "Word 1266 (\"earlier\") appears 1 time.\n",
      "Word 1388 (\"recovery\") appears 1 time.\n",
      "Word 1443 (\"cen\") appears 1 time.\n",
      "Word 1446 (\"cror\") appears 1 time.\n",
      "Word 1488 (\"address\") appears 1 time.\n",
      "Word 1491 (\"agarwal\") appears 2 time.\n",
      "Word 1493 (\"press\") appears 1 time.\n",
      "Word 1494 (\"brief\") appears 2 time.\n",
      "Word 1496 (\"recov\") appears 1 time.\n",
      "Word 1503 (\"community\") appears 1 time.\n",
      "Word 1505 (\"healthcar\") appears 1 time.\n",
      "Word 1591 (\"ensur\") appears 1 time.\n",
      "Word 1688 (\"blam\") appears 1 time.\n",
      "Word 1689 (\"sanitatio\") appears 1 time.\n",
      "Word 1690 (\"attack\") appears 1 time.\n",
      "Word 1691 (\"empow\") appears 1 time.\n",
      "Word 1692 (\"chairperso\") appears 1 time.\n",
      "Word 1693 (\"param\") appears 1 time.\n",
      "Word 1694 (\"iyer\") appears 1 time.\n",
      "Word 1695 (\"cook\") appears 1 time.\n",
      "Word 1696 (\"meal\") appears 1 time.\n",
      "Word 1697 (\"serv\") appears 1 time.\n",
      "Word 1698 (\"ngo\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.021*\"india\" + 0.015*\"military\" + 0.013*\"tim\" + 0.013*\"say\" + 0.013*\"governm\" + 0.013*\"billio\" + 0.012*\"sta\" + 0.012*\"offic\" + 0.010*\"expenditur\" + 0.008*\"repor\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.020*\"india\" + 0.020*\"say\" + 0.019*\"typ\" + 0.015*\"icmr\" + 0.012*\"kit\" + 0.011*\"research\" + 0.010*\"covid\" + 0.010*\"tes\" + 0.010*\"coronaviru\" + 0.010*\"procur\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.019*\"tobacco\" + 0.016*\"produc\" + 0.016*\"adverti\" + 0.013*\"crick\" + 0.010*\"india\" + 0.010*\"health\" + 0.010*\"bcci\" + 0.007*\"tim\" + 0.006*\"director\" + 0.006*\"ask\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.018*\"india\" + 0.015*\"tes\" + 0.012*\"crea\" + 0.011*\"tim\" + 0.010*\"kit\" + 0.010*\"say\" + 0.009*\"sta\" + 0.009*\"repor\" + 0.008*\"governm\" + 0.008*\"fak\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.038*\"cas\" + 0.024*\"covid\" + 0.019*\"say\" + 0.018*\"sta\" + 0.016*\"repor\" + 0.016*\"total\" + 0.016*\"coronaviru\" + 0.015*\"india\" + 0.014*\"mini\" + 0.012*\"positiv\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.029*\"china\" + 0.020*\"india\" + 0.017*\"chi\" + 0.015*\"south\" + 0.011*\"ship\" + 0.009*\"isla\" + 0.009*\"ocea\" + 0.007*\"philippi\" + 0.007*\"pro\" + 0.007*\"regio\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.011*\"india\" + 0.011*\"say\" + 0.010*\"week\" + 0.008*\"sta\" + 0.008*\"pric\" + 0.008*\"outpu\" + 0.008*\"shu\" + 0.007*\"company\" + 0.007*\"barrel\" + 0.007*\"bord\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.027*\"fund\" + 0.023*\"bank\" + 0.016*\"mutual\" + 0.013*\"liquidity\" + 0.013*\"say\" + 0.011*\"facility\" + 0.009*\"india\" + 0.009*\"tim\" + 0.007*\"spread\" + 0.007*\"cror\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
